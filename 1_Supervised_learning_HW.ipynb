{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_Supervised_learning_HW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huseynovramilx/LinkShortener/blob/master/1_Supervised_learning_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmpZeRhwGmqX"
      },
      "source": [
        "# Homework #1\n",
        "## Introduction to supervised learning \n",
        "\n",
        "This colaboratory contains Homework #1 of the Machine Learning course, which is due **September 19, Sunday, midnight (23:59 EET time)**. To complete the homework, extract **(File -> Download .ipynb)** and submit to the course webpage.\n",
        "\n",
        "**NB! Links to your colaboratory will not be accepted as a solution!**\n",
        "\n",
        "## Submission's rules:\n",
        "\n",
        "1.   Please, submit only .ipynb that you extract from the Colaboratory.\n",
        "2. Run your homework exercises before submitting (output should be present, preferably restart the kernel and press run all the cells).\n",
        "3. Do not change the description of tasks in red (even if there is a typo|mistake|etc).\n",
        "4. Please, make sure to avoid unnecessary long printouts.\n",
        "5. Each task should be solved right under the question of the task and not elsewhere.\n",
        "6. Solutions to both regular and bonus exercises should be submitted in one IPYNB file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAatB_cDv6-X"
      },
      "source": [
        "##List of Homework's exercises:\n",
        "1. [EX1](#scrollTo=tz9XASPxeqDC) - 2 points\n",
        "2. [EX2](#scrollTo=BGVGqZGpxmzQ&uniqifier=1#) - 2 points\n",
        "3. [EX3](#scrollTo=1YXt-Gxw9UY7&uniqifier=1) - 2 points\n",
        "4. [EX4](#scrollTo=7p4GMeGK-QGL&uniqifier=1) - 1 points\n",
        "5. [EX5](#scrollTo=nqV2c5sDc_f2&uniqifier=1) - 3 points\n",
        "6. [Bonus 1](#scrollTo=_2T9ydozzcb-&uniqifier=1) - 2 points\n",
        "7. [Bonus 2](#scrollTo=UkOtofaRjH8P&uniqifier=1) - up to 5 points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJIhqUhr40Ks"
      },
      "source": [
        "### Homework setup: \n",
        "Here we will load necessary libraries (NumPy and Pandas) and MNIST dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqp9Kj1g4yFb"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from seaborn import countplot # to plot more or less good-looking histogram\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category = RuntimeWarning)\n",
        "\n",
        "import os\n",
        "\n",
        "# old school TF\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "# Supress warnings by TF 1.x\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) # credit to Dmitry Lekhovitsky\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n",
        "\n",
        "images = mnist.train.images\n",
        "labels = mnist.train.labels\n",
        "print(f\"images are of shape: {images.shape} and labels: {labels.shape}\")\n",
        "\n",
        "# Subsample the images\n",
        "train_images = images[0:2000,:]\n",
        "train_labels = labels[0:2000]\n",
        "\n",
        "test_images = images[2000:3000,:]\n",
        "test_labels = labels[2000:3000]\n",
        "\n",
        "# Get the test image\n",
        "test_image = test_images[0]\n",
        "test_label = test_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz9XASPxeqDC"
      },
      "source": [
        "## Homework exercise 1 (2 points): KNN\n",
        "One very popular variation of Nearest Neighbour is K-nearest neighbour. In this algorithm a label for a new instance is chosen by majority vote by **`k`** of its nearest neighbors. \n",
        "\n",
        "The actual algorithm is not very different from vanila nearest neighbour:\n",
        "\n",
        "1. Compute distances to all points in the dataset\n",
        "2. Find the **`k`** closest points (you may consider using `np.argsort` function)\n",
        "3. Report the most popular label from these **`k`**. (maybe `np.bincount` can help)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtuWU_bTw8bf"
      },
      "source": [
        "<font color='red'>**(Homework exercise 1- a)** Implement the aformentioned algorithm in the cell below (1.0 point)</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J91vFM8yeqDC"
      },
      "source": [
        "def dist(img1, img2):\n",
        "  ##### YOUR CODE STARTS #####\n",
        "  return ...\n",
        "  ##### YOUR CODE ENDS ##### (please do not delete this line)\n",
        "\n",
        "def classify_knn(image, k):\n",
        "  ##### YOUR CODE STARTS #####\n",
        "  all_distances = ...\n",
        "  ...\n",
        "  prediction = ...\n",
        "  ##### YOUR CODE ENDS ##### (please do not delete this line)\n",
        "  return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpP9LIhWeqDE"
      },
      "source": [
        "Test the function on `test_image`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1ZjNWxzeqDF"
      },
      "source": [
        "print(f\"Predicted class for the first image is {classify_knn(test_image, 10)} and the true label is {test_label}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkIbSADBjCpB"
      },
      "source": [
        "<font color='red'>**(Homework exercise 1- b)** Modify the function `classify_knn` adding a print statement that outputs labels of K nearest labels. Report 10 nearest neighbours  for the `test_image`. Explain its output in the cell below. (0.5 points) </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzlSQ4zPqj-J"
      },
      "source": [
        "Answer to (b): ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwbtses-xJ5q"
      },
      "source": [
        "<font color='red'>**(Homework exercise 1- c)** Classify all test images and store them into a separate variable `test_predicted`, choose `k` = 5. Compute accuracy of your KNN model. **NB, don't forget to uncomment all print statements inside the function!** (0.5 points) </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqLUqqBIxJkp"
      },
      "source": [
        "##### YOUR CODE STARTS #####\n",
        "test_predicted = ...\n",
        "n_correct = ...\n",
        "knn_accuracy = ...\n",
        "##### YOUR CODE ENDS ##### (please do not delete this line)\n",
        "print(f\"Final accuracy of our nearest neighbor classifier is {knn_accuracy}. Not bad!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGVGqZGpxmzQ"
      },
      "source": [
        "## Homework exercise 2 (2 points): exploring misclassified examples\n",
        "<font color='red'>**(Homework exercise 2- a)** Modify the visualisation code that we used during the practice session to visualise a grid of example images from different classes. Now, instead of random examples from each class, visualise misclassified examples from each class. For example, in the first column visualise images that had true label `0` but were classified as something else, in the second column, show examples of images that had label `1` but were misclassified into another class and so on. Add a title to each small image, in the following format `true_label, predicted_label` e.g. \"0, 6\" - image of class 0 was classified as 6. (1.5 points)\n",
        "\n",
        "**NB! you need a variable `test_predicted` to exist from the previous exercise to complete this exericse.** </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXAKr_qY5dzh"
      },
      "source": [
        "num_classes = 10\n",
        "samples_per_class = 7 # Number of images from each class we want to see\n",
        "fig, axs = plt.subplots(samples_per_class, num_classes, figsize=(10.0, 8.0))\n",
        "for i in range(num_classes):\n",
        "    ##### YOUR CODE STARTS #####\n",
        "    ...\n",
        "    ##### YOUR CODE ENDS ##### (please do not delete this line)\n",
        "plt.setp(axs,xticks=[],yticks=[]) # set all axes off\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73G5hFzrxrVc"
      },
      "source": [
        "<font color='red'>**(Homework exercise 2- b)** What is your take away from this figure? Are all classes equally missclassified? Why? Are there any classes that KNN confuses more often, why? (0.5 points) </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmNqSRNiysh-"
      },
      "source": [
        "Answer to (b):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YXt-Gxw9UY7"
      },
      "source": [
        "## Homework exercise 3 (2 points): visualising linear regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj4fUVAG1PAN"
      },
      "source": [
        "A small setup first:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbYCpxCDz_55"
      },
      "source": [
        "# Plotting as in ggplot2\n",
        "!pip install -q plotnine\n",
        "from plotnine import *\n",
        "\n",
        "# Synthetic data we created in the practice session\n",
        "example_data = pd.DataFrame({'distance':[1,2,3,4,5], 'fare_amount':[2,4,5,4,5]})\n",
        "\n",
        "# Slope and intercept estimated from the example_data\n",
        "w1 = np.sum((example_data.distance - np.mean(example_data.distance))*(example_data.fare_amount - np.mean(example_data.fare_amount)))/(np.sum((example_data.distance - np.mean(example_data.distance))**2))\n",
        "intercept = np.mean(example_data.fare_amount) - w1*np.mean(example_data.distance)\n",
        "\n",
        "# Test data we synthesised only to colour space\n",
        "test_data = pd.concat([pd.DataFrame({'distance': np.repeat(x, 71), 'fare_amount': np.linspace(start=0, stop=7, num=71)}) for x in np.linspace(start=0, stop=6, num=61)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvug-opoyHSA"
      },
      "source": [
        "\n",
        "<font color='red'>**(Homework exercise 3- a)** use previously computed coefficients `w1` and `intercept` of the linear regression model to predict the fare amount in the `test_data`. (1 point)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPzCHrC-9kuW"
      },
      "source": [
        "##### YOUR CODE STARTS #####\n",
        "test_data['predicted_amount'] = ...\n",
        "##### YOUR CODE ENDS ##### (please do not delete this line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jsc7JbcphX5"
      },
      "source": [
        "<font color='red'>**(Homework exercise 3- b)** visualise these predictions as well as linear regression line the way we have done it for Decision Tree in the practice session. (0.5 points)\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utfQ_3GDplfx"
      },
      "source": [
        "##### YOUR CODE STARTS #####\n",
        "fig = (\n",
        "    ggplot(...)\n",
        ")\n",
        "##### YOUR CODE ENDS ##### (please do not delete this line)\n",
        "fig + geom_abline(intercept = intercept, slope = w1, color=\"black\", linetype=\"dashed\", size=1.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY97fEcmqAW9"
      },
      "source": [
        "<font color='red'>**(Homework exercise 3- c)** Interpret the resulting figure (what is going on there?). (0.5 points)\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t-BZGT9FYeb"
      },
      "source": [
        "Answer to (c): "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiyv1wdqImo-"
      },
      "source": [
        "## Preparation for homework exercises 4 and 5\n",
        "Next we will work with real-world dataset collected from taxis operating in New York City"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVU6bxgsNzEh"
      },
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "link = 'https://drive.google.com/file/d/1XBBNQ6wnaz5W-h8qbL-2_4MNchGR8YCI' # The shareable link"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmMEiS7ICgRB"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':'1XBBNQ6wnaz5W-h8qbL-2_4MNchGR8YCI'}) \n",
        "downloaded.GetContentFile('nyc_data.zip')\n",
        "\n",
        "# After archive has been downloaded\n",
        "# unzip it\n",
        "!unzip nyc_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkSYWHwZEG9j"
      },
      "source": [
        "* `train_2M.csv` contains 2 million observations from NYC dataset (6 independent variables and fare_amount that we need to predict).\n",
        "* `test.csv` contains new observations, for which we have to estimate `fare_amount` based on train data.\n",
        "* `sample_submission.csv` - a sample submission file in the correct format (columns `key` and `fare_amount`). Every row in this file matches every row in `test.csv`.\n",
        "* `model.pickel` - file that contains trained model saved as a pickle (we are going to deal with it later)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p4GMeGK-QGL"
      },
      "source": [
        "## Homework exercise 4 (1 point): read and explore `model.pickel`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rsa9ojOlgmmk"
      },
      "source": [
        "<font color='red'> **(Homework exercise 4- a)** read in `model.pickel` file that you have downloaded from `nyc_data.zip` using `pickle.load()` function. (0.5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iezeRiy9gl_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a29fecaa-4d05-4fa1-ef91-54022d617165"
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "##### YOUR CODE STARTS #####\n",
        "filename = ...\n",
        "\n",
        "##### YOUR CODE ENDS ##### (please do not delete this line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearRegression from version 0.20.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJQbGVDs-1vS"
      },
      "source": [
        "<font color='red'> **(Homework exercise 4- b)** next, explore the object using function `dir` and answer the following questions:\n",
        "* <font color='red'> Which model was saved into this object?  \n",
        "* <font color='red'> How many coefficients it has and what are their values?\n",
        "* <font color='red'>Can you find out which features have been used for training?\n",
        "\n",
        "<font color='red'>(0.5 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PoebBH_ii4H"
      },
      "source": [
        "Answers to (b): "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9MiatCvf_Qz"
      },
      "source": [
        "### Setting up Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wEnpDansSd2"
      },
      "source": [
        "You need to have an account on Kaggle.com, before you proceed to the last exercise. You need to create **a new API token** at Kaggle.com (your account page). Download the kaggle.json file and fill in the **key** and your username in the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqAUm2XZEz7D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf0f1ca-1b7c-4a77-ad2b-700848a59108"
      },
      "source": [
        "import json\n",
        "\n",
        "!mkdir /root/.kaggle/\n",
        "token = {\"username\": \"YOUR USERNAME\", \"key\": \"YOUR KEY\"}\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fDy-ghRhlvv"
      },
      "source": [
        "In order to sign up for a NYC Taxi competition you need to accept the rules by cliking on \"Late submission\" button in the upper right corner: https://www.kaggle.com/c/new-york-city-taxi-fare-prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2FromHiSLB4"
      },
      "source": [
        "Make a test submission to ensure that the submission mechanism works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULF0BN3LCtSE"
      },
      "source": [
        "!kaggle competitions submit -c new-york-city-taxi-fare-prediction -f sample_submission.csv -m \"Sample submission test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4HijXgyspzs"
      },
      "source": [
        "Now you can check `My submissions` tab on the website: https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/submissions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXvcLJyNSRzH"
      },
      "source": [
        "## Read in the NYC data and perform basic preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQXdJrPvDMrZ"
      },
      "source": [
        "%%time \n",
        "\n",
        "# note that we use only 1M out of 2M records\n",
        "train =  pd.read_csv('train_2M.csv', parse_dates=[\"pickup_datetime\"], nrows = 1_000_000) # the first row will automatically be interpreted as a header\n",
        "\n",
        "# functions that add two new features abs_diff_longitude and abs_diff_latitude\n",
        "def add_travel_vector_features(df):\n",
        "    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n",
        "    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n",
        "\n",
        "# adding two new features to train\n",
        "add_travel_vector_features(train)\n",
        "\n",
        "# reading in test and adding two new features to test\n",
        "test = pd.read_csv('test.csv')\n",
        "add_travel_vector_features(test)\n",
        "\n",
        "# removing not available values and outliers\n",
        "train = train.dropna(how = 'any', axis = 'rows')\n",
        "train = train[(train.abs_diff_longitude < 5.0) & (train.abs_diff_latitude < 5.0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqV2c5sDc_f2"
      },
      "source": [
        "## Homework exercise 5 (3 points): cross-validation algorithm\n",
        "<font color='red'> In the classroom were cheating on our validation data when we hand-picked the number of decision trees in the previous example (as we used validation data multiple times). The honest and better way of finding a good hyperparameter (depth of the tree) is a **cross-validation algorithm**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSbeesjBy89b"
      },
      "source": [
        "<font color='red'> **(Homework exercise 5- a)** Implement the cross-validation algorithm using lecture slides and hints in comments. (2 points) </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G96lG0IbfG87"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "max_depths = [1, 2, 5, 8, 9, 10, 11, 12, 13, 15, 20]\n",
        "\n",
        "# 4-fold cross validation\n",
        "for param in max_depths:\n",
        "  print(f'Calculating RMSE for tree with a depth {param}...')\n",
        "  ##### YOUR CODE STARTS #####\n",
        "  # create a vector of fold indexes \n",
        "  # with length of this vector equal to number of rows in training data\n",
        "  # your can use np.concatenate and np.repeat functions\n",
        "  folds_indx = ...\n",
        "  # for dataset with 8 entries you should get:\n",
        "  # the following vector[0, 0, 1, 1, 2, 2, 3, 3]\n",
        "  # chunks can be unequal if the number of rows is not divisible by 4\n",
        "\n",
        "  # randomly shuffle the obtained indeces\n",
        "  np.random.shuffle(folds_indx)\n",
        "  \n",
        "  # number of folds\n",
        "  n_folds = 4\n",
        "\n",
        "  # initialise variable that will hold RMSEs for each fold\n",
        "  fold_RMSEs = np.zeros(n_folds)\n",
        "  for fold_indx in np.arange(n_folds):\n",
        "\n",
        "    # split data into train_X, train_y and val_X, val_y depending on the fold\n",
        "    # use previously generated folds_indx to fetch the right rows\n",
        "    train_X = ...\n",
        "    train_y = ...\n",
        "    val_X = ...\n",
        "    val_y = ...\n",
        "\n",
        "    # train the decision tree with max_depth = param\n",
        "    dtr = ...\n",
        "\n",
        "    # fit the decision tree on training data\n",
        "    dtr.fit(...)\n",
        "\n",
        "    # predict validation data\n",
        "    val_predictions = ...\n",
        "\n",
        "    # calculate RMSE for this fold\n",
        "    fold_RMSEs[fold_indx] = ...\n",
        "  ##### YOUR CODE ENDS ##### (please do not delete this line)\n",
        "\n",
        "  print(f'Average validation RMSE for {param} of trees is {np.mean(fold_RMSEs)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urDuREWxK_ro"
      },
      "source": [
        "<font color='red'> **(Homework exercise 5- b)** Based on above results train the `DecisionTreeRegressor` on the entire training data with new, more optimal number of trees. Predict the test set and submit the results to Kaggle. Print out your new leaderboard score, which should be smaller than 4.02083. Interpret your results (1 point) </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OfvpyJKIN_j"
      },
      "source": [
        "##### YOUR CODE STARTS #####\n",
        "...\n",
        "\n",
        "!kaggle ...\n",
        "print(f\"My new score is {}\")\n",
        "##### YOUR CODE ENDS ##### (please do not delete this line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVi9oSaKGtmS"
      },
      "source": [
        "Interpretation of results:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMmhuxN4iw2L"
      },
      "source": [
        "# Bonus exercises\n",
        "*(NB, these are optional exercises!)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2T9ydozzcb-"
      },
      "source": [
        "## Bonus exercise 1 (2 bonus points):\n",
        "\n",
        "<font color='red'> Visualising misclassified examples can help to debug the classification algorithm. But misclassified examples may have different probabilities. In this bonus exercise (optional) try modifying code we have written for the homework exercise 2 so that title now would include probability of a true class and of a wrong class. You would probably need to change the code of `classify_knn` function. </font> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkOtofaRjH8P"
      },
      "source": [
        "## Bonus exercise 2 (up to 5 points): the grand challenge\n",
        "<font color='red'> Try to get into top 300 places on public leaderboard (RMSE < 3.04) using different ML algorithms with different parameters, more features, more data, better preprocessing. Here are some ideas for improvement:\n",
        "* Use more data (we only took 1M out of 2M, there are 53M more on the website)\n",
        "* Do more preprocessing (remember negative prices or unrealistic numbers of passengers?)\n",
        "* Use more/better features (e.g. euclidean distance, or google what is haversine distance)\n",
        "* Use some other regression algorithm (e.g. look into RandomForestRegressor from sklearn.ensemble)\n",
        "* Tune parameters of these algorithms\n",
        "* Try something else!\n",
        "</font> \n",
        "\n",
        "<font color='red'>You should make a small post here with code and elaborate explanations of what you have tried (do it even you did not manage to break into top 300). **Report your final leaderboard rank**. Number of points would depend on quality of your explanations and the resulting rank.</font> \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2T2eINijEhg"
      },
      "source": [
        "# Hint:\n",
        "R = 6378\n",
        "\n",
        "def haversine_distance(lon1, lon2, lat1, lat2):\n",
        "    \"\"\"\n",
        "    Calculate the great circle distance between two points\n",
        "    on the earth (specified in decimal degrees)\n",
        "\n",
        "    All args must be of equal length.    \n",
        "    \n",
        "    source: https://stackoverflow.com/a/29546836\n",
        "\n",
        "    \"\"\"\n",
        "    # Convert latitude and longitude to radians\n",
        "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
        "\n",
        "    # Find the differences\n",
        "    dlon = lon2 - lon1\n",
        "    dlat = lat2 - lat1\n",
        "\n",
        "    # Apply the formula \n",
        "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
        "    # Calculate the angle (in radians)\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "    # Convert to kilometers\n",
        "    km = R * c\n",
        "    \n",
        "    return km"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JZfcKFAs82h"
      },
      "source": [
        "# Comments (optional feedback to the course instructors)\n",
        "Here, please, leave your comments regarding the homework, possibly answering the following questions: \n",
        "* how much time did you spend on this homework?\n",
        "* was it too hard/easy for you?\n",
        "* what would you suggest to add or remove?\n",
        "* anything else you would like to tell us"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22VPt-05s-Yg"
      },
      "source": [
        "Your comments:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_57iGEWYZ4_H"
      },
      "source": [
        "# <font color='red'>  End of the homework. Please don't delete this cell.</font>"
      ]
    }
  ]
}